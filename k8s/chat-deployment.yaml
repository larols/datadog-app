apiVersion: apps/v1
kind: Deployment
metadata:
  name: datadog-app-chat
  namespace: datadog-app
spec:
  replicas: 1
  selector:
    matchLabels:
      app: datadog-app-chat
  template:
    metadata:
      labels:
        app: datadog-app-chat
      annotations:
        ad.datadoghq.com/datadog-app-chat.logs: '[{"source":"python","service":"datadog-app-chat"}]'
    spec:
      enableServiceLinks: false  # reduce noisy *_SERVICE_* env (e.g., OTEL vars)
      serviceAccountName: datadog-app-sa
      containers:
        - name: datadog-app-chat
          image: laols/datadog-app-chat:latest
          ports:
            - containerPort: 5050
          env:
            # --- Core APM identity ---
            - name: DD_SERVICE
              value: datadog-app-chat
            - name: DD_ENV
              value: production
            - name: DD_VERSION
              value: "${VERSION}"

            # --- Send traces/LLM Obs to the Datadog Agent ---
            - name: DD_TRACE_AGENT_URL
              value: 'http://datadog-agent.default:8126'

            # --- Enable LLM Observability (via Agent) ---
            - name: DD_LLMOBS_ENABLED
              value: "true"
            - name: DD_LLMOBS_ML_APP
              value: "datadog-app-chat"

            # --- Log correlation ---
            - name: DD_LOGS_INJECTION
              value: "true"

            # --- Optional performance/diagnostics flags you already used ---
            - name: DD_RUNTIME_METRICS_ENABLED
              value: "true"
            - name: DD_TRACE_ENABLED
              value: "true"
            - name: DD_DYNAMIC_INSTRUMENTATION_ENABLED
              value: "true"
            - name: DD_PROFILING_ENABLED
              value: "true"
            - name: DD_PROFILING_TIMELINE_ENABLED
              value: "true"
            - name: DD_CODE_ORIGIN_FOR_SPANS_ENABLED
              value: "true"

            # OpenAI API key (from secret)
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: openai-api
                  key: OPENAI_API_KEY

          # Use your appâ€™s health endpoint
          readinessProbe:
            httpGet:
              path: /healthz
              port: 5050
            initialDelaySeconds: 5
            periodSeconds: 10
          livenessProbe:
            httpGet:
              path: /healthz
              port: 5050
            initialDelaySeconds: 15
            periodSeconds: 20

          resources:
            requests:
              cpu: 50m
              memory: 128Mi
            limits:
              cpu: 500m
              memory: 512Mi
